{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Arabic Sign Language - Landmark Training (Kaggle â†’ TFLite)\n",
        "\n",
        "Notebook steps:\n",
        "- Authenticate Kaggle and download dataset outside the app\n",
        "- Extract 21 hand landmarks per image with MediaPipe, normalize to 63 features\n",
        "- Train a Dense classifier (63 â†’ N classes)\n",
        "- Convert to TensorFlow Lite and export `arabic_sign_lstm.tflite` and `labels.json`\n",
        "\n",
        "Note: Keep labels order consistent across training and app.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip -q install kaggle mediapipe opencv-python-headless==4.10.0.84 numpy pandas scikit-learn tensorflow==2.15.*\n",
        "\n",
        "import os, json, zipfile, shutil, sys\n",
        "from pathlib import Path\n",
        "print(\"âœ… Environment ready\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Kaggle authentication (upload your kaggle.json)\n",
        "from google.colab import files\n",
        "\n",
        "if not Path('/root/.kaggle/kaggle.json').exists():\n",
        "    print('ðŸ“¥ Please upload kaggle.json (Profile â†’ Account â†’ Create New API Token)')\n",
        "    uploaded = files.upload()  # choose kaggle.json\n",
        "    os.makedirs('/root/.kaggle', exist_ok=True)\n",
        "    shutil.move('kaggle.json', '/root/.kaggle/kaggle.json')\n",
        "    os.chmod('/root/.kaggle/kaggle.json', 0o600)\n",
        "\n",
        "print('âœ… Kaggle API configured')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download and unzip the dataset\n",
        "DATASET_REF = 'muhammadalbrham/rgb-arabic-alphabets-sign-language-dataset'\n",
        "DL_DIR = Path('dataset')\n",
        "DL_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "!kaggle datasets download -d {DATASET_REF} -p {str(DL_DIR)}\n",
        "\n",
        "# Unzip (force overwrite)\n",
        "for z in DL_DIR.glob('*.zip'):\n",
        "    print('Unzipping', z)\n",
        "    !unzip -o {str(z)} -d {str(DL_DIR)}\n",
        "\n",
        "print('âœ… Dataset ready at', str(DL_DIR.resolve()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inspect dataset structure and build labels\n",
        "import os\n",
        "\n",
        "# Infer class directories (adjust if dataset layout differs)\n",
        "class_dirs = []\n",
        "for root, dirs, files in os.walk(DL_DIR):\n",
        "    # consider leaf dirs with image files\n",
        "    if any(f.lower().endswith(('.png', '.jpg', '.jpeg')) for f in files):\n",
        "        class_dirs.append(Path(root))\n",
        "\n",
        "# Heuristic: classes are the immediate subfolders of DL_DIR (adjust if needed)\n",
        "classes = sorted({p.name for p in class_dirs if p.parent == DL_DIR})\n",
        "print('Found classes:', classes)\n",
        "\n",
        "# If heuristic fails, you can manually define classes like:\n",
        "# classes = [\"alef\",\"baa\",\"taa\", ...]\n",
        "\n",
        "with open('labels.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(classes, f, ensure_ascii=False, indent=2)\n",
        "print('âœ… labels.json saved with', len(classes), 'classes')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract 21 hand landmarks (x,y,z) â†’ 63 features per image\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import mediapipe as mp\n",
        "\n",
        "with open('labels.json','r',encoding='utf-8') as f:\n",
        "    labels = json.load(f)\n",
        "\n",
        "hands = mp.solutions.hands.Hands(\n",
        "    static_image_mode=True,\n",
        "    max_num_hands=1,\n",
        "    model_complexity=1,\n",
        "    min_detection_confidence=0.5\n",
        ")\n",
        "\n",
        "rows = []\n",
        "\n",
        "def normalize_landmarks(xyz):\n",
        "    # Match app logic closely: center at wrist (idx 0), scale by max L2 distance\n",
        "    arr = np.array(xyz, dtype=np.float32)  # (21,3)\n",
        "    origin = arr[0].copy()\n",
        "    arr -= origin\n",
        "    scale = np.max(np.linalg.norm(arr, axis=1)) + 1e-6\n",
        "    arr /= scale\n",
        "    return arr.reshape(-1)  # (63,)\n",
        "\n",
        "for cls in labels:\n",
        "    img_dir = DL_DIR/cls\n",
        "    if not img_dir.exists():\n",
        "        print('Skip (missing):', img_dir)\n",
        "        continue\n",
        "    files = [p for p in img_dir.iterdir() if p.suffix.lower() in {'.png','.jpg','.jpeg'}]\n",
        "    for p in files:\n",
        "        img = cv2.imread(str(p))\n",
        "        if img is None:\n",
        "            continue\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        res = hands.process(img)\n",
        "        if not res.multi_hand_landmarks:\n",
        "            continue\n",
        "        lm = res.multi_hand_landmarks[0].landmark\n",
        "        xyz = [(pt.x, pt.y, getattr(pt, 'z', 0.0)) for pt in lm]\n",
        "        feats = normalize_landmarks(xyz)\n",
        "        row = {f'f{i}': float(v) for i, v in enumerate(feats)}\n",
        "        row['label'] = cls\n",
        "        rows.append(row)\n",
        "\n",
        "hands.close()\n",
        "\n",
        "landmarks_df = pd.DataFrame(rows)\n",
        "landmarks_df.to_csv('dataset_landmarks.csv', index=False)\n",
        "print('âœ… Saved landmarks CSV with shape:', landmarks_df.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train Dense model (63 â†’ num_classes)\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "landmarks_df = pd.read_csv('dataset_landmarks.csv')\n",
        "feature_cols = [c for c in landmarks_df.columns if c.startswith('f')]\n",
        "X = landmarks_df[feature_cols].values.astype('float32')\n",
        "y_text = landmarks_df['label'].values\n",
        "\n",
        "le = LabelEncoder()\n",
        "y_idx = le.fit_transform(y_text)\n",
        "num_classes = len(le.classes_)\n",
        "y = tf.keras.utils.to_categorical(y_idx, num_classes)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y_idx, random_state=42\n",
        ")\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(63,)),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(num_classes, activation='softmax'),\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=25,\n",
        "    batch_size=64,\n",
        "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)]\n",
        ")\n",
        "\n",
        "# Persist labels (order matters)\n",
        "with open('labels.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(list(le.classes_), f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print('âœ… Training complete. Val acc:', float(history.history['val_accuracy'][-1]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert to TFLite and export\n",
        "import tensorflow as tf\n",
        "from google.colab import files\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "# Optional optimizations (uncomment to try size/speed trade-offs)\n",
        "# converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "# converter.target_spec.supported_types = [tf.float16]\n",
        "\n",
        "tflite_model = converter.convert()\n",
        "with open('arabic_sign_lstm.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "print('âœ… Saved arabic_sign_lstm.tflite and labels.json')\n",
        "\n",
        "# Download to your computer\n",
        "files.download('arabic_sign_lstm.tflite')\n",
        "files.download('labels.json')\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
